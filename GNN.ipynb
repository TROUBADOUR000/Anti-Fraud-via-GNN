{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:03:51.084935500Z",
     "start_time": "2023-12-27T14:03:10.907981800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, GINConv, SAGEConv, SGConv\n",
    "from torch import  nn\n",
    "\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor\n",
    "from typing import Union\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"extended_graphs_data.pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "    file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:03:51.827358400Z",
     "start_time": "2023-12-27T14:03:51.051853400Z"
    }
   },
   "id": "e30d68fc9165140b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[579157, 51], edge_index=[2, 335118], edge_attr=[335118], y=[579157], train_mask=[231662], valid_mask=[154442], test_mask=[193053], edge_direct=[335118])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:03:52.094976900Z",
     "start_time": "2023-12-27T14:03:51.833568200Z"
    }
   },
   "id": "f8e40c55ab90278b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:03:52.702203400Z",
     "start_time": "2023-12-27T14:03:51.905645800Z"
    }
   },
   "id": "835a230a8a091e6f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "split_idx = {'train':data.train_mask, 'valid':data.valid_mask, 'test':data.test_mask}\n",
    "data = data.to(device)\n",
    "train_idx = split_idx['train'].to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:04:11.115679100Z",
     "start_time": "2023-12-27T14:03:52.626342100Z"
    }
   },
   "id": "a64c879bf56d642b",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4492\n",
      "2671\n",
      "1821\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(data.y.cpu().numpy() == 1))\n",
    "print(np.sum(data.y[data.train_mask].cpu().numpy() == 1))\n",
    "print(np.sum(data.y[data.valid_mask].cpu().numpy() == 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:04:11.576290300Z",
     "start_time": "2023-12-27T14:04:11.128522500Z"
    }
   },
   "id": "2577d00efdff9d1a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        myConv = SAGEConv\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(myConv(in_channels, hidden_channels, cached=True))\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns = torch.nn.ModuleList()\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                myConv(hidden_channels, hidden_channels, cached=True))\n",
    "            if self.batchnorm: \n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        # self.convs.append(myConv(hidden_channels, out_channels, cached=True))\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, 32),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(32, out_channels),\n",
    "        )\n",
    "\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index: Union[Tensor, SparseTensor]):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            if self.batchnorm: \n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        # x = self.convs[-1](x, edge_index)\n",
    "        x = self.regression(x)\n",
    "        \n",
    "        return x.log_softmax(dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:04:11.688018200Z",
     "start_time": "2023-12-27T14:04:11.513284500Z"
    }
   },
   "id": "6eb3aca300294255",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch_geometric.utils.subgraph import k_hop_subgraph\n",
    "\n",
    "def train(model, data, train_idx, optimizer):\n",
    "    # data.y is labels of shape (N, ) \n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    nodeandneighbor, edge_index, node_map, mask = k_hop_subgraph(\n",
    "        train_idx, 5, data.edge_index, relabel_nodes=True, num_nodes=data.x.size(0)\n",
    "    )\n",
    "    \n",
    "    out = model(\n",
    "        data.x[nodeandneighbor],\n",
    "        data.edge_index\n",
    "    )[train_idx]\n",
    "    \n",
    "    # out = model(data.x, data.adj_t)[train_idx]\n",
    "    loss = F.nll_loss(out, data.y[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:04:11.847434900Z",
     "start_time": "2023-12-27T14:04:11.603926400Z"
    }
   },
   "id": "51dde67c1682a468",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, data, split_idx):\n",
    "    # data.y is labels of shape (N, )\n",
    "    model.eval()\n",
    "    \n",
    "    out = model(data.x, data.edge_index)\n",
    "        \n",
    "    y_pred = out.exp()  # (N,num_classes)\n",
    "    \n",
    "    losses = dict()\n",
    "    for key in ['train', 'valid']:\n",
    "        node_id = split_idx[key]\n",
    "        losses[key] = F.nll_loss(out[node_id], data.y[node_id]).item()\n",
    "            \n",
    "    return losses, y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:04:11.852677500Z",
     "start_time": "2023-12-27T14:04:11.665785100Z"
    }
   },
   "id": "a7b43d29a4a46c07",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parameters = {'lr':0.001\n",
    "              , 'num_layers':3\n",
    "              , 'hidden_channels':256\n",
    "              , 'dropout':0.1\n",
    "              , 'batchnorm': True\n",
    "              , 'l2':1e-7\n",
    "             }\n",
    "epochs = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:04:11.957483300Z",
     "start_time": "2023-12-27T14:04:11.723925500Z"
    }
   },
   "id": "3d8b93605d8861e1",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  initialized\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 18\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel  initialized\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m---> 18\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     losses, out \u001B[38;5;241m=\u001B[39m test(model, data, split_idx)\n\u001B[0;32m     20\u001B[0m     train_loss, valid_loss \u001B[38;5;241m=\u001B[39m losses[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m], losses[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "Cell \u001B[1;32mIn[8], line 13\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, data, train_idx, optimizer)\u001B[0m\n\u001B[0;32m      7\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m      9\u001B[0m nodeandneighbor, edge_index, node_map, mask \u001B[38;5;241m=\u001B[39m k_hop_subgraph(\n\u001B[0;32m     10\u001B[0m     train_idx, \u001B[38;5;241m5\u001B[39m, data\u001B[38;5;241m.\u001B[39medge_index, relabel_nodes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_nodes\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mx\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     11\u001B[0m )\n\u001B[1;32m---> 13\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnodeandneighbor\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m[train_idx]\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# out = model(data.x, data.adj_t)[train_idx]\u001B[39;00m\n\u001B[0;32m     19\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mnll_loss(out, data\u001B[38;5;241m.\u001B[39my[train_idx])\n",
      "File \u001B[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[7], line 43\u001B[0m, in \u001B[0;36mGNN.forward\u001B[1;34m(self, x, edge_index)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, edge_index: Union[Tensor, SparseTensor]):\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, conv \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]):\n\u001B[1;32m---> 43\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatchnorm: \n\u001B[0;32m     45\u001B[0m             x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbns[i](x)\n",
      "File \u001B[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mE:\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:131\u001B[0m, in \u001B[0;36mSAGEConv.forward\u001B[1;34m(self, x, edge_index, size)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001B[39;00m\n\u001B[0;32m    130\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpropagate(edge_index, x\u001B[38;5;241m=\u001B[39mx, size\u001B[38;5;241m=\u001B[39msize)\n\u001B[1;32m--> 131\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlin_l\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    133\u001B[0m x_r \u001B[38;5;241m=\u001B[39m x[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_weight \u001B[38;5;129;01mand\u001B[39;00m x_r \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mE:\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:130\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    126\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;124;03m        x (torch.Tensor): The input features.\u001B[39;00m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "para_dict = parameters\n",
    "model_para = parameters.copy()\n",
    "model_para.pop('lr')\n",
    "model_para.pop('l2')        \n",
    "model = GNN(in_channels = data.x.size(-1), out_channels = 2, **model_para).to(device)\n",
    "\n",
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['l2'])\n",
    "min_valid_loss = 1000000.0\n",
    "best_model_path = 'model.pth' \n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "print(f'Model  initialized')\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    loss = train(model, data, train_idx, optimizer)\n",
    "    losses, out = test(model, data, split_idx)\n",
    "    train_loss, valid_loss = losses['train'], losses['valid']\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    if valid_loss < min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    print(f'Epoch: {epoch:}, '\n",
    "        f'Loss: {loss:.6f}, '\n",
    "        f'Train: {train_loss:.6f}, '\n",
    "        f'Valid: {valid_loss:.6f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:04:28.555311400Z",
     "start_time": "2023-12-27T14:04:11.837828600Z"
    }
   },
   "id": "7012c999d18b8fb0",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs + 1), valid_losses, label='Valid Loss')\n",
    "\n",
    "\n",
    "plt.title('Loss Variation Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:04:28.647989700Z",
     "start_time": "2023-12-27T14:04:28.565765500Z"
    }
   },
   "id": "9d6d1934afa7c39e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test2(model, data):\n",
    "    # data.y is labels of shape (N, )\n",
    "    model.eval()\n",
    "    \n",
    "    out = model(data.x, data.edge_index)\n",
    "        \n",
    "    y_pred = out.exp()  # (N,num_classes)\n",
    "            \n",
    "    return y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-27T14:04:28.580545600Z"
    }
   },
   "id": "3e013f782c5faa84",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = GNN(in_channels = data.x.size(-1), out_channels = 2, **model_para)\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model = model.to(device)\n",
    "\n",
    "out = test2(model, data)\n",
    "\n",
    "# Extract predictions for training and validation sets\n",
    "preds_train, preds_valid = out[data.train_mask].cpu().numpy(), out[data.valid_mask].cpu().numpy()\n",
    "y_train, y_valid = data.y[data.train_mask].cpu().numpy(), data.y[data.valid_mask].cpu().numpy()\n",
    "\n",
    "# Threshold predictions to obtain binary values (0 or 1)\n",
    "threshold = 0.5\n",
    "binary_preds_train = (preds_train[:, 1] > threshold).astype(int)\n",
    "binary_preds_valid = (preds_valid[:, 1] > threshold).astype(int)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy_train = accuracy_score(y_train, binary_preds_train)\n",
    "accuracy_valid = accuracy_score(y_valid, binary_preds_valid)\n",
    "\n",
    "# Compute ROC AUC\n",
    "train_auc = roc_auc_score(y_train, preds_train[:, 1])\n",
    "valid_auc = roc_auc_score(y_valid, preds_valid[:, 1])\n",
    "\n",
    "# Print the results\n",
    "print('Train Accuracy:', accuracy_train)\n",
    "print('Valid Accuracy:', accuracy_valid)\n",
    "print('Train ROC AUC:', train_auc)\n",
    "print('Valid ROC AUC:', valid_auc)\n",
    "# 231662 228991\n",
    "# 154442 152621"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-27T14:04:28.602286500Z"
    }
   },
   "id": "9224aaea561eca0b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
