{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:04.935007900Z",
     "start_time": "2023-12-21T06:28:58.897367900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "import pickle\n",
    "from typing import Optional, Callable, List\n",
    "import os.path as osp\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y', 'edge_type', 'edge_index', 'train_mask', 'test_mask']\n"
     ]
    }
   ],
   "source": [
    "# 读取 npz 文件\n",
    "d = np.load('data.npz', allow_pickle=True)\n",
    "print(list(d.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:04.970926300Z",
     "start_time": "2023-12-21T06:29:04.925162100Z"
    }
   },
   "id": "e2bdb3de5e68fb94"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4492   381612   193053\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(d['y'] == 1), ' ', np.sum(d['y'] == 0), ' ', np.sum(d['y'] == -100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:05.034654400Z",
     "start_time": "2023-12-21T06:29:04.967692600Z"
    }
   },
   "id": "b2caaa2b25ffaffc"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (579157, 17)\n",
      "y shape: (579157,)\n",
      "edge_index shape: (167559, 2)\n",
      "edge_type shape: (167559,)\n",
      "train_mask shape: (386104,)\n",
      "test_mask shape: (193053,)\n"
     ]
    }
   ],
   "source": [
    "# 获取数据\n",
    "x = d['x']\n",
    "y = d['y']\n",
    "edge_index = d['edge_index']\n",
    "edge_type = d['edge_type']\n",
    "# edge_timestamp = data['edge_timestamp']\n",
    "train_mask = d['train_mask']\n",
    "test_mask = d['test_mask']\n",
    "\n",
    "# 输出数据的形状\n",
    "print(\"x shape:\", x.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"edge_index shape:\", edge_index.shape)\n",
    "print(\"edge_type shape:\", edge_type.shape)\n",
    "# print(\"edge_timestamp shape:\", edge_timestamp.shape)\n",
    "print(\"train_mask shape:\", train_mask.shape)\n",
    "print(\"test_mask shape:\", test_mask.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:05.175831800Z",
     "start_time": "2023-12-21T06:29:05.032637300Z"
    }
   },
   "id": "56ec12b51731b9c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def degree_feat(edge_index, x):\n",
    "    adj = csr_matrix(\n",
    "        (np.ones(edge_index.shape[0]), (edge_index[:, 0], edge_index[:, 1])),\n",
    "        shape=(x.shape[0], x.shape[0]),\n",
    "    )\n",
    "    out_degree, in_degree = adj.sum(axis=1), adj.sum(axis=0).T\n",
    "    return out_degree, in_degree"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:05.205696800Z",
     "start_time": "2023-12-21T06:29:05.175831800Z"
    }
   },
   "id": "3541ee7f6b78c163"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def edge_type_feat(edge_type, edge_index, x):\n",
    "    edge_type_adj = csr_matrix(\n",
    "        (edge_type, (edge_index[:, 0], edge_index[:, 1])),\n",
    "        shape=(x.shape[0], x.shape[0]),\n",
    "    )\n",
    "    edge_type_feat = np.zeros((x.shape[0], 11))\n",
    "    data, indptr = edge_type_adj.data, edge_type_adj.indptr\n",
    "    for i in range(x.shape[0]):\n",
    "        row = data[indptr[i] : indptr[i + 1]]\n",
    "        unique, counts = np.unique(row, return_counts=True)\n",
    "        for j, k in zip(unique, counts):\n",
    "            edge_type_feat[i, j - 1] = k\n",
    "    return edge_type_feat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:05.208224700Z",
     "start_time": "2023-12-21T06:29:05.193681600Z"
    }
   },
   "id": "e801c2ca6acc9248"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "out_degree, in_degree = degree_feat(edge_index, x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:05.266958200Z",
     "start_time": "2023-12-21T06:29:05.205696800Z"
    }
   },
   "id": "b8bc1f9da2a21c63"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def read_xygraphp1(downsample_ratio):\n",
    "    names = ['data.npz']\n",
    "    items = [np.load(name) for name in names]\n",
    "    \n",
    "    x = items[0]['x']\n",
    "    y = items[0]['y'].reshape(-1,1)\n",
    "    edge_index = items[0]['edge_index']\n",
    "    edge_type = items[0]['edge_type']\n",
    "    np.random.seed(42)\n",
    "    train_mask_t = items[0]['train_mask']\n",
    "    np.random.shuffle(train_mask_t)\n",
    "    \n",
    "    x = np.concatenate((x, edge_type_feat(edge_type, edge_index, x)), axis=1)\n",
    "    x = np.concatenate((x, in_degree), axis=1)\n",
    "    \n",
    "    # imbalance\n",
    "    positive_indices = (y == 1).nonzero()[0]\n",
    "    # 获取类别为0的样本索引\n",
    "    negative_indices = (y == 0).nonzero()[0]\n",
    "    # 下采样类别为0的样本，使得0的个数是1的 downsample_ratio 倍\n",
    "    num_negative_samples = int(len(positive_indices) * downsample_ratio)\n",
    "    downsampled_negative_indices = torch.randint(len(negative_indices), size=(num_negative_samples,))\n",
    "    # 映射下采样后的样本索引\n",
    "    downsampled_indices = np.concatenate([positive_indices, negative_indices[downsampled_negative_indices]])\n",
    "    \n",
    "    print(\"***\", len(downsampled_indices))\n",
    "    \n",
    "    num_samples = len(downsampled_indices)\n",
    "    num_train_samples = int(num_samples * 0.8)\n",
    "    indices_perm = torch.randperm(num_samples)\n",
    "    train_mask = downsampled_indices[indices_perm[:num_train_samples]]\n",
    "    valid_mask = downsampled_indices[indices_perm[num_train_samples:]]\n",
    "    \n",
    "    # train_mask = train_mask_t[:int(len(train_mask_t)/10*6)]\n",
    "    # valid_mask = train_mask_t[int(len(train_mask_t)/10*6):]\n",
    "    test_mask = items[0]['test_mask']\n",
    "\n",
    "    x = torch.tensor(x, dtype=torch.float).contiguous()\n",
    "    y = torch.tensor(y, dtype=torch.int64)\n",
    "    edge_index = torch.tensor(edge_index.transpose(), dtype=torch.long).contiguous()\n",
    "    edge_type = torch.tensor(edge_type, dtype=torch.long)\n",
    "    train_mask = torch.tensor(train_mask, dtype=torch.long)\n",
    "    test_mask = torch.tensor(test_mask, dtype=torch.long)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_type, y=y)\n",
    "    data.train_mask = train_mask\n",
    "    data.valid_mask = valid_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:05.282704800Z",
     "start_time": "2023-12-21T06:29:05.267966600Z"
    }
   },
   "id": "c149f63990d0eb31"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class XYGraphP1(InMemoryDataset):\n",
    "\n",
    "    url = ''\n",
    "\n",
    "    def __init__(self, root: str, name: str, \n",
    "                 transform: Optional[Callable] = None,\n",
    "                 pre_transform: Optional[Callable] = None):\n",
    "        \n",
    "        self.name = name\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "\n",
    "    def process(self):\n",
    "        # 修改采样比例\n",
    "        data = read_xygraphp1(5)\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:05.302741500Z",
     "start_time": "2023-12-21T06:29:05.284709Z"
    }
   },
   "id": "81abb7dbb737ff5f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 40428\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"\\ndata = T.ToSparseTensor()(data)\\ndata.adj_t = data.adj_t.to_symmetric()\\n# data.edge_index = edge_index\\n\\nif dataset in ['XYGraphP1']:\\n    x = data.x\\n    x = (x - x.mean(0)) / x.std(0)\\n    data.x = x\\n\\nif data.y.dim() == 2:\\n    data.y = data.y.squeeze(1)\\n\""
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = XYGraphP1(root='', name='', transform=T.ToSparseTensor())\n",
    "data = read_xygraphp1(8)\n",
    "'''\n",
    "data = T.ToSparseTensor()(data)\n",
    "data.adj_t = data.adj_t.to_symmetric()\n",
    "# data.edge_index = edge_index\n",
    "\n",
    "if dataset in ['XYGraphP1']:\n",
    "    x = data.x\n",
    "    x = (x - x.mean(0)) / x.std(0)\n",
    "    data.x = x\n",
    "\n",
    "if data.y.dim() == 2:\n",
    "    data.y = data.y.squeeze(1)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:14.847930Z",
     "start_time": "2023-12-21T06:29:05.300238400Z"
    }
   },
   "id": "5c2025bdb3cf3a02"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[579157, 29], edge_index=[2, 167559], edge_attr=[167559], y=[579157, 1], train_mask=[32342], valid_mask=[8086], test_mask=[193053])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:14.876501200Z",
     "start_time": "2023-12-21T06:29:14.836390900Z"
    }
   },
   "id": "3e37267d4a4a099d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3616\n",
      "28726\n",
      "876\n",
      "7210\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(data.y[data.train_mask].cpu().numpy() == 1))\n",
    "print(np.sum(data.y[data.train_mask].cpu().numpy() == 0))\n",
    "print(np.sum(data.y[data.valid_mask].cpu().numpy() == 1))\n",
    "print(np.sum(data.y[data.valid_mask].cpu().numpy() == 0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:14.969017700Z",
     "start_time": "2023-12-21T06:29:14.852472800Z"
    }
   },
   "id": "a567a18569ad8a56"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"graphs_balance_data.pkl\", \"wb\") as file:\n",
    "# with open(\"graphs_data2.pkl\", \"wb\") as file:\n",
    "    pickle.dump(data, file)\n",
    "    file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:15.081908100Z",
     "start_time": "2023-12-21T06:29:14.884013900Z"
    }
   },
   "id": "480e3ca7e449e888"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nclass GCN(torch.nn.Module):\\n    def __init__(self\\n                 , in_channels\\n                 , hidden_channels\\n                 , out_channels\\n                 , num_layers\\n                 , dropout\\n                 , batchnorm=True):\\n        super(GCN, self).__init__()\\n\\n        self.convs = torch.nn.ModuleList()\\n        self.convs.append(gnn.SAGEConv(256, hidden_channels, cached=True))\\n        self.batchnorm = batchnorm\\n        if self.batchnorm:\\n            self.bns = torch.nn.ModuleList()\\n            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\\n        for _ in range(num_layers - 2):\\n            self.convs.append(\\n                gnn.SAGEConv(hidden_channels, hidden_channels, cached=True))\\n            if self.batchnorm: \\n                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\\n        self.convs.append(gnn.SAGEConv(hidden_channels, out_channels, cached=True))\\n        \\n        self.conv1 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1)\\n        self.pool1 = nn.MaxPool1d(kernel_size=1, stride=1)\\n        self.drop1 = nn.Dropout(p=0.1)\\n        \\n        self.conv2 = nn.Conv1d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1)\\n        self.pool2 = nn.MaxPool1d(kernel_size=1, stride=1)\\n        self.drop2 = nn.Dropout(p=0.1)\\n        \\n        self.regression = nn.Sequential(\\n            nn.Linear(128, 64),\\n            nn.Dropout(0.2),\\n            nn.ELU(),\\n            nn.Linear(64, 16),\\n            # nn.ELU(),\\n            # nn.Linear(16, out_channels),\\n        )\\n        \\n        # self.convs.append(gnn.SAGEConv(16, out_channels, cached=True))\\n        \\n        self.dropout = dropout\\n\\n    def reset_parameters(self):\\n        for conv in self.convs:\\n            conv.reset_parameters()\\n        if self.batchnorm:\\n            for bn in self.bns:\\n                bn.reset_parameters()\\n\\n    def forward(self, x, edge_index: Union[Tensor, SparseTensor]):\\n\\n        for i, conv in enumerate(self.convs[:-1]):\\n            x = conv(x, edge_index)\\n            if self.batchnorm: \\n                x = self.bns[i](x)\\n            x = F.elu(x)\\n            x = F.dropout(x, p=self.dropout, training=self.training)\\n        x = self.convs[-1](x, edge_index)\\n        \\n        x = x.view(x.size(0), x.size(1), -1)\\n        x = self.drop1(self.pool1(F.elu(self.conv1(x))))\\n        x = self.drop2(self.pool2(F.relu(self.conv2(x))))\\n        x = x.view(x.size(0), -1)\\n        \\n        x = self.regression(x)\\n        x = self.convs[-1](x, edge_index)\\n        # print(x.shape)\\n        \\n        return x.log_softmax(dim=-1)\\n'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(gnn.SAGEConv(256, hidden_channels, cached=True))\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns = torch.nn.ModuleList()\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                gnn.SAGEConv(hidden_channels, hidden_channels, cached=True))\n",
    "            if self.batchnorm: \n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(gnn.SAGEConv(hidden_channels, out_channels, cached=True))\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=1, stride=1)\n",
    "        self.drop1 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=1, stride=1)\n",
    "        self.drop2 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(64, 16),\n",
    "            # nn.ELU(),\n",
    "            # nn.Linear(16, out_channels),\n",
    "        )\n",
    "        \n",
    "        # self.convs.append(gnn.SAGEConv(16, out_channels, cached=True))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index: Union[Tensor, SparseTensor]):\n",
    "\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            if self.batchnorm: \n",
    "                x = self.bns[i](x)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        \n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        x = self.drop1(self.pool1(F.elu(self.conv1(x))))\n",
    "        x = self.drop2(self.pool2(F.relu(self.conv2(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.regression(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        return x.log_softmax(dim=-1)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T06:29:15.141568800Z",
     "start_time": "2023-12-21T06:29:15.088836800Z"
    }
   },
   "id": "1a5d6d0413599099"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
